{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6092ab21-3227-4c34-98e8-50589076faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q mlflow torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256a936a-618b-4510-8180-df9e169c3074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchinfo import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91cb11f-b60d-4c73-bb26-b893ae7bcdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, padding=2)  # Padding added to keep size as 28x28\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, padding=2)  # Padding added to keep size as 14x14\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2250572e-7a00-42af-9ee0-8af027b2fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = {\n",
    "    'exp_name': 'Mnist-test',\n",
    "    'batchSize': 128,\n",
    "    'img_shape': [3,224,224],\n",
    "    'epoch': 20,\n",
    "    'early_stop': 3,\n",
    "    'lr': 0.00001,\n",
    "    'optim': 'Adam',\n",
    "    'secheduler': 'CosineAnnealingLR',\n",
    "    'loss': 'CrossEntropyLoss'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b39002a-4f23-4b67-b330-0e9d15bcaf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset(CIFAR10)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train = torchvision.datasets.MNIST(root='./', train=True, download=True, transform=transform) \n",
    "test = torchvision.datasets.MNIST(root='./', train=False, download=False, transform=transform)\n",
    "\n",
    "split=0.8\n",
    "train_size=int(len(train)*split)\n",
    "traindata, valdata = data.random_split(train, [train_size, len(train)-train_size])\n",
    "#traindata, valdata = train_test_split(train, test_size = 0.2, random_state = 111)\n",
    "\n",
    "trainLoader = data.DataLoader(traindata, batch_size=train_info['batchSize'], shuffle=True, num_workers=2)\n",
    "validLoader = data.DataLoader(valdata, batch_size=train_info['batchSize'], shuffle=True,num_workers=2)\n",
    "testLoader = data.DataLoader(test, batch_size=train_info['batchSize'], shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ee590-e8e0-4ac3-b45b-ed735214e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize img\n",
    "img = train[1][0]\n",
    "\n",
    "plt.imshow(img.squeeze(0),cmap='binary')\n",
    "plt.show()\n",
    "print(train[1][1])\n",
    "print(img.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007b5ed-68b9-4330-b1be-f0526dc80cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "device ='cuda:0' if torch.cuda.is_available() else 'cpu' #check cuda\n",
    "print(device,'is available!\\n')\n",
    "model = Net().to(device)\n",
    "#summary(model, input_size=(128, 1, 32, 32))\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),betas=(0.9, 0.98), lr=train_info['lr'])\n",
    "scheduler=lr_scheduler.CosineAnnealingLR(optimizer,5)\n",
    "criterion= nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e61959-4aa1-47ab-880e-010fdf93f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary(model, input_size=(128, 1, 28, 28)))\n",
    "with open(\"model_info.txt\", \"w\") as f:\n",
    "    f.write(summary(model, input_size=(128, 1, 28, 28)).__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd25ea8c-e537-45e5-8ecc-bbd760520721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "#store loss inf\n",
    "loss={'train_loss':[],'valid_loss':[],'lr':[]}        \n",
    "\n",
    "#early_stopping\n",
    "patience=5\n",
    "earlystop=0\n",
    "best_loss=float('inf')\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "# mlflow set url\n",
    "mlflow.set_tracking_uri(\"http://mlflow-web:5000/\")\n",
    "\n",
    "if not mlflow.get_experiment_by_name(train_info['exp_name']):\n",
    "    mlflow.create_experiment(train_info['exp_name'])\n",
    "\n",
    "mlflow.set_experiment(train_info['exp_name'])\n",
    "\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # para\n",
    "    mlflow.log_param(\"data set\", \"Torchvision-Mnsit\")\n",
    "    mlflow.log_param(\"Batch Size\", train_info['batchSize'])\n",
    "    if device != 'cpu':\n",
    "        mlflow.log_param(\"gpu\", \"enabled\")\n",
    "    mlflow.log_param(\"epoch\",train_info['epoch'])\n",
    "    mlflow.log_param(\"optimizer\", train_info['optim'])\n",
    "    mlflow.log_param(\"init_lr\", train_info['lr'])\n",
    "    mlflow.log_param(\"scheduler\", train_info['secheduler'])\n",
    "    mlflow.log_param(\"loss function\", train_info['loss'])\n",
    "    mlflow.log_artifact(\"model_info.txt\")\n",
    "    \n",
    "    for epoch in range(train_info['epoch']):\n",
    "        #model train\n",
    "        model.train()\n",
    "        tmp=[]\n",
    "        with tqdm(trainLoader,leave=False) as tepoch:\n",
    "            for inputs, target in tepoch:\n",
    "                #set tqdm description\n",
    "                tepoch.set_description(f'TrainEpoch{epoch+1:3d}')\n",
    "                inputs, target=inputs.to(device), target.to(device)\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                output = model(inputs)\n",
    "                crit = criterion(output, target)\n",
    "\n",
    "                tmp.append(crit.cpu().item())\n",
    "\n",
    "                crit.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                tepoch.set_postfix({'loss':'{0:.3f}'.format(np.average(tmp))})\n",
    "                \n",
    "                \n",
    "            \n",
    "        scheduler.step()\n",
    "        mlflow.log_metric(\"train_loss\", np.average(tmp), epoch+1)\n",
    "        loss['train_loss'].append(np.average(tmp))\n",
    "        #model valid\n",
    "        model.eval()\n",
    "        tmp=[]\n",
    "        with tqdm(validLoader,leave=False) as vepoch:\n",
    "            for inputs, target in vepoch:\n",
    "                vepoch.set_description(f'ValidEpoch{epoch+1:3d}')\n",
    "                inputs,target=inputs.to(device), target.to(device)\n",
    "\n",
    "                output=model(inputs)\n",
    "                crit=criterion(output,target)\n",
    "\n",
    "                tmp.append(crit.cpu().item())\n",
    "                vepoch.set_postfix({'loss':'{0:.3f}'.format(np.average(tmp))})\n",
    "\n",
    "        \n",
    "\n",
    "        loss['valid_loss'].append(np.average(tmp))\n",
    "        loss['lr'].append(scheduler.get_last_lr())\n",
    "        mlflow.log_metric(\"valid_loss\", np.average(tmp), epoch+1)\n",
    "        mlflow.log_metric(\"learning_rate\", scheduler.get_last_lr()[0], epoch+1)\n",
    "        # earlystopping\n",
    "        cur_loss=np.average(tmp)\n",
    "        if cur_loss>best_loss:\n",
    "            earlystop+=1\n",
    "            if earlystop>= patience:\n",
    "                print('Early stopping!')\n",
    "                mlflow.log_param(\"Early_Stopping_Happened\", f'finish in {epoch+1} epochs!' )\n",
    "                break\n",
    "        else:\n",
    "            earlystop=0\n",
    "            best_loss=cur_loss\n",
    "        \n",
    "    mlflow.pytorch.log_model(model, \"pytorch-model\")\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model-test\"\n",
    "    model_details = mlflow.register_model(model_uri, 'Mnist')\n",
    "    mlflow.log_param(\"model save\", model_details.source)\n",
    "    #print(model_details)\n",
    "        \n",
    "    print('Finished Training')\n",
    "    test_acc={}\n",
    "    classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    # Test\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with tqdm(testLoader,leave=True) as tepoch:\n",
    "        for inputs, labels in tepoch:\n",
    "            inputs, labels= inputs.to(device), labels.to(device)\n",
    "            output=model(inputs)\n",
    "            _, predicted = torch.max(output,1)\n",
    "            total+=labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            c=(predicted==labels).squeeze()\n",
    "    \n",
    "            for i in range(labels.size(0)):\n",
    "                label=labels[i].item()\n",
    "                if label not in test_acc:\n",
    "                    test_acc[label]=[0,0]\n",
    "                else:\n",
    "                    test_acc[label][0]+=c[i].item()\n",
    "                    test_acc[label][1]+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        print('Accuracy of %10s : %2d %%' % (classes[i], 100 * test_acc[i][0] / test_acc[i][1]))\n",
    "    print()\n",
    "    print('Test Dataset : %d %%' % (100 * correct / total))\n",
    "    mlflow.log_metric(\"test accuracy\", (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
